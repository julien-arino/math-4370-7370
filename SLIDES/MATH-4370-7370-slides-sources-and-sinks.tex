\documentclass[aspectratio=169]{beamer}

%\documentclass[handout]{beamer}
%% To make 4 per page
%\usepackage{pgfpages}
%\mode<handout>{\setbeamercolor{background canvas}{bg=white}}
%\pgfpagesuselayout{4 on 1}[letterpaper,landscape]%,border shrink=5mm]

\input{slides_setup_nonLightBoard_whiteBG.tex}
% To cross reference from other slide files
\zexternaldocument{MATH-4370-7370-slides-03-eigenpairs-similarity}
\zexternaldocument{MATH-4370-7370-slides-06-nonnegative-matrices}

% To have theorems and everything derived prefixed by the slide set
% number
\renewcommand{\thetheorem}{8.\arabic{theorem}}

\title{An example from metapopulations}
\author{Julien Arino}
\date{Fall 2023}

%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\begin{document}

% The title page
\begin{frame}[noframenumbering,plain]
  \begin{tikzpicture}[remember picture,overlay]
    \node[above right,inner sep=0pt] at (current page.south west)
    {
        \includegraphics[width=\paperwidth]{title-page-picture.png}
    };
\end{tikzpicture}
	\titlepage
\end{frame}
\addtocounter{page}{-1}
  
  
\begin{frame}{Outline}
	  \tableofcontents[hideallsubsections]
\end{frame}
\addtocounter{page}{-1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Why do this?}
	This is mostly about dynamics
	\vfill
	Looping back to our first few lectures: \emph{matrices are everywhere}!
	\vfill
	This is a (rather abstract) problem in theoretical ecology (or mathematical ecology?)
	\vfill
	We will be using a surprising number of results we have already seen
\end{frame}

%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
\section{Position of the problem}
\begin{frame}{Rael \& Taylor (2018)}
	{\footnotesize\emph{A flow network model for animal movement on a landscape with application to invasion}, Theoretical Ecology}
	\vfill
	\[
	P_i' = P_iB(P_i)+\sum_{j=1}^N 
	a_{ji}P_jm(P_j,P_i)
	-P_i\sum_{j=1}^N a_{ij}m(P_i,P_j)
	\]
	where
	\[
	m(P_i, P_j) = \frac{\max\{0, \pi(P_i)-\pi(P_j)\}}{d_{ij}}
	\qquad \pi(P_i) = \frac{P_i}{K_i}
	\]
	$d_{ij}$ distance from $i$ to $j$, $K_i$ carrying capacity
	\[
	B(P_i) = \begin{cases}
	r_i\left(1-\dfrac{P_i}{K_i}\right) & \textrm{sources} \\
	-r_i & \textrm{sinks}
	\end{cases}
	\]
\end{frame}
	
\maxFrameImage{FIGS/source-sinks-nicolas-steve}
	
\begin{frame}{Position of the problem}
	Assume a metapopulation of patches connected through transport of individuals between them
	\vfill
	Some patches are sources, others are sinks:
	\begin{itemize}
		\item Population tends to persist in sources
		\item Population tends to vanish in sinks
	\end{itemize}
	\vfill
	\emph{Ceteris paribus}, does there exist a ratio of the number of source to sink patches s.t. the population of the coupled system persists?
\end{frame}

\begin{frame}{Something like this...}
    \begin{center}
        \begin{tikzpicture}
            \node[inner sep=-30pt] (sink1) at (0,0)
                {\includegraphics[width=.3\textwidth]{FIGS/sink-patch.png}};
                \node[inner sep=-30pt] (sink2) at (5.5,-1.25)
                {\includegraphics[width=.3\textwidth]{FIGS/sink-patch.png}};
                \node[inner sep=-30pt] (source1) at (8,2)
                {\includegraphics[width=.3\textwidth]{FIGS/source-patch.png}};
                \node[inner sep=-30pt] (source2) at (9.5,-2)
                {\includegraphics[width=.3\textwidth]{FIGS/source-patch.png}};
                \node[inner sep=-30pt] (source3) at (3.5,1.5)
                {\includegraphics[width=.3\textwidth]{FIGS/source-patch.png}};
				\path [line, very thick, bend right=5] (sink1) to (sink2);
				\path [line, very thick, bend right=25] (sink1) to (source2);
				\path [line, very thick, bend right=25] (sink2) to (source3);
				\path [line, very thick, bend right=25] (source2) to (source3);
				\path [line, very thick, bend right=25] (source1) to (source3);
				\path [line, very thick, bend right=25] (source3) to (sink1);
        \end{tikzpicture}
    \end{center}
\end{frame}


\begin{frame}
	\textbf{Obvious special cases}
\end{frame}

\begin{frame}{This should not be good for the species}
    \begin{center}
        \begin{tikzpicture}
            \node[inner sep=-30pt] (sink1) at (0,0)
                {\includegraphics[width=.3\textwidth]{FIGS/sink-patch.png}};
                \node[inner sep=-30pt] (sink2) at (5.5,-1.25)
                {\includegraphics[width=.3\textwidth]{FIGS/sink-patch.png}};
                \node[inner sep=-30pt] (source1) at (8,2)
                {\includegraphics[width=.3\textwidth]{FIGS/sink-patch.png}};
                \node[inner sep=-30pt] (source2) at (9.5,-2)
                {\includegraphics[width=.3\textwidth]{FIGS/sink-patch.png}};
                \node[inner sep=-30pt] (source3) at (3.5,1.5)
                {\includegraphics[width=.3\textwidth]{FIGS/sink-patch.png}};
				\path [line, very thick, bend right=5] (sink1) to (sink2);
				\path [line, very thick, bend right=25] (sink1) to (source2);
				\path [line, very thick, bend right=25] (sink2) to (source3);
				\path [line, very thick, bend right=25] (source2) to (source3);
				\path [line, very thick, bend right=25] (source1) to (source3);
				\path [line, very thick, bend right=25] (source3) to (sink1);
        \end{tikzpicture}
    \end{center}
\end{frame}

\begin{frame}{This is probably good for the species}
    \begin{center}
        \begin{tikzpicture}
            \node[inner sep=-30pt] (sink1) at (0,0)
                {\includegraphics[width=.3\textwidth]{FIGS/source-patch.png}};
                \node[inner sep=-30pt] (sink2) at (5.5,-1.25)
                {\includegraphics[width=.3\textwidth]{FIGS/source-patch.png}};
                \node[inner sep=-30pt] (source1) at (8,2)
                {\includegraphics[width=.3\textwidth]{FIGS/source-patch.png}};
                \node[inner sep=-30pt] (source2) at (9.5,-2)
                {\includegraphics[width=.3\textwidth]{FIGS/source-patch.png}};
                \node[inner sep=-30pt] (source3) at (3.5,1.5)
                {\includegraphics[width=.3\textwidth]{FIGS/source-patch.png}};
				\path [line, very thick, bend right=5] (sink1) to (sink2);
				\path [line, very thick, bend right=25] (sink1) to (source2);
				\path [line, very thick, bend right=25] (sink2) to (source3);
				\path [line, very thick, bend right=25] (source2) to (source3);
				\path [line, very thick, bend right=25] (source1) to (source3);
				\path [line, very thick, bend right=25] (source3) to (sink1);
        \end{tikzpicture}
    \end{center}
\end{frame}



\section[Sources-sinks model]{A metapopulation of sources and sinks with explicit movement}

\begin{frame}{Model for $N$ patches}
	W.l.o.g.: $S\geq 0$ first patches are sources, $N-S$ remaining are sinks [w.l.o.g. but not that trivial nonetheless]
	\vfill
	\textbf{Sources:}
	\begin{subequations}\label{sys:simple_model}
	\begin{equation}
	P_i' = r_iP_i\left(1-\frac{P_i}{K_i}\right)+\sum_{j=1}^N m_{ij}P_j,
	\quad i=1,\ldots,S
	\end{equation}
	\vfill
	\textbf{Sinks:}
	\begin{equation}
	P_i' = -r_iP_i +\sum_{j=1}^N m_{ij}P_j,\quad i=S+1,\ldots,N
	\end{equation}
	\end{subequations}
	\vfill
	\[
	m_{ii} = -\sum_{\substack{j=1\\j\neq i}}^N m_{ji}
	\]
\end{frame}	
	

\begin{frame}{Vector form (v1)}
	$\bP=(P_1,\ldots,P_N)^T$
	\vfill
	\[
	\bP' = \bG(\bP)\bP+\M\bP
	\]
	where
	\[
	\bG(\bP) =
	\diag\left(
	r_1\left(1-\frac{P_1}{K_1}\right),\ldots,r_S\left(1-\frac{P_S}{K_S}\right),
	-r_{S+1},\ldots,-r_N
	\right)
	\]
	\[
	\M =
	\begin{pmatrix}
	-\sum\limits_{\substack{j=1\\j\neq 1}}^N m_{j1} & m_{12} & \cdots & m_{1N} \\
	m_{21} & -\sum\limits_{\substack{j=1\\j\neq 2}}^N m_{j2} & \cdots & m_{2N} \\
	& & \ddots & \\
	m_{N1} & m_{N2} & \cdots & -\sum\limits_{\substack{j=1\\j\neq N}}^N m_{jN}
	\end{pmatrix}
	\]
\end{frame}
	
\begin{frame}{Vector form (v2)}
	$\bP_s=(P_1,\ldots,P_S)^T$ (sources), \quad $\bP_t =(P_{S+1},\ldots,P_N)$ (sinks)
	\vfill
	\begin{align*}
	\bP_s' &= \bG_s(\bP_s)\bP_s+\M_s\bP_s+\M_{st}\bP_t \\
	\bP_t' &= -\D_t\bP_t+\M_{ts}\bP_s+\M_t\bP_t
	\end{align*}
	where
	\[
	\bG_s(\bP_s) =
	\diag\left(
	r_1\left(1-\frac{P_1}{K_1}\right),\ldots,r_S\left(1-\frac{P_S}{K_S}\right)
	\right)
	\]
	\[
	\D_t = \diag\left(r_{S+1},\ldots,r_N\right)
	\]
	\begin{equation}\label{eq:M_blocks}
	\begin{pmatrix}
	\M_s & \M_{st} \\ \M_{ts} & \M_t
	\end{pmatrix} = \M
	\end{equation}
\end{frame}


\begin{frame}{Main result we want to get to}
	\begin{theorem}\label{th:main_result}
		$\exists$ a unique critical interval $\S_{int}\subset(0,N)\subset\IR$ s.t. if the number of source patches $S<\min(\S_{int})$, the population-free equilibrium (PFE) $(P_1,\ldots,P_N)=(0,\ldots,0)$ of \eqref{sys:simple_model} is locally asymptotically stable and if $S>\max(\S_{int})$, the PFE is unstable
		\vskip0.5cm
		If, additionally, the digraph of patches is strongly connected, then $\S_{int}$ reduces to a single point $S^c$ and the PFE is globally asymptotically stable in the case that $S<S^c$; in the case that $S>S^c$, there is a unique component-wise positive equilibrium $\bP^*$ that is GAS with respect to $\IR_+^N\setminus\{0\}$
		\end{theorem}
		
\end{frame}


%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
\section{The movement matrix}
\begin{frame}{Properties of the movement matrix $\M$}
	\begin{lemma}\label{lemma:mvt_matrix}
		\begin{enumerate}
			\item $0\in\sigma(\M)$ corresponding to left e.v. $\11^T$ \hfill[$\sigma$ spectrum] \label{lemma:mvt_matrix_0ev}
			\item $-\M$ is a singular M-matrix \label{lemma:mvt_matrix_MMmatrix}
			\item $0=s(\M)\in\sigma(\M)$ \hfill[$s$ spectral abscissa] \label{lemma:mvt_matrix_SB_eq0}
			\item If $\M$ irreducible, then $s(\M)$ has multiplicity 1 \label{lemma:mvt_matrix_SB_mult1}
		\end{enumerate}
	\end{lemma}
\end{frame}



\begin{frame}{Proof of Lemma~\ref{lemma:mvt_matrix}}
\ref{lemma:mvt_matrix_0ev}. The result is obvious: all column sums of $\M$ equal zero, i.e., $\nbOne^T\M=0\nbOne^T$
\vfill
\noindent\ref{lemma:mvt_matrix_SB_eq0}. Using the Gershgorin Disk Theorem ~\ref{th:Gershgorin} on $\M$ indicates that all Gershgorin disks are tangent to the imaginary axis at $(0,0)$. As 0 is an eigenvalue of $\M$, it follows that $s(\M)=0$
\vfill
\noindent\ref{lemma:mvt_matrix_SB_mult1}. This is a direct consequence of using the Perron-Frobenius Theorem~\ref{th:PerronFrobenius} on the essentially nonnegative matrix $\M$
\end{frame}

\begin{frame}{Proof of Lemma~\ref{lemma:mvt_matrix} (cont'd)}
	\noindent\ref{lemma:mvt_matrix_MMmatrix}. 
	From the Gershgorin Disk Theorem ~\ref{th:Gershgorin}, all eigenvalues of $-\M$ belong to disks that lie to the right of the imaginary axis and, from the zero column sums, are tangent to that axis at $(0,0)$
	\vfill
	Now consider $-\M+\varepsilon\II$, for $\varepsilon>0$. 
	This shifts the centers of all Gershgorin disks to the right by $\varepsilon$ Theorem~\ref{th:HJ_problem_1_2_P8} but does not change their radii, so all disks now lie strictly to the right of the imaginary axis 
	\vfill
	Thus all eigenvalues of $-\M+\varepsilon\II$ have positive real parts
	\vfill
	Furthermore, $-\M$ and $-\M+\varepsilon\II$ are of class $Z_n$ (Definition~\ref{def:Z_n}). 
	Theorem~\ref{th:Fiedler2008}(\ref{th:Fiedler2008_18}) $\implies$ $-\M+\varepsilon\II$ is of class $K$, i.e., an M-matrix.
	Since this is true for all $\varepsilon>0$, Theorem~\ref{th:Fiedler2008_K0}(\ref{th:Fiedler2008_K0_1}) implies that $-\M$ is of class $K_0$. 
	So $-\M$ is an M-matrix and it is singular
\end{frame}

\begin{frame}{Properties of the movement matrix $\M$ (cont'd)}
	\begin{proposition}[$D$ a diagonal matrix]\label{prop:perturbation_mvtMatrix}
		\begin{enumerate}
			\item $s(\M+d\II)=d$, $\forall d\in\IR$ \label{prop:perturbation_mvtMatrix_d}
			\item $s(\M+D)\in\sigma(\M+D)$ associated to $\bv>\b0$. If $\M$ irreducible, $s(\M+D)$ has  multiplicity 1 and is associated to $\bv\gg \b0$ \label{prop:perturbation_mvtMatrix_D}
			\item $\diag (D)\gg \b0$ $\implies$ $D-\M$ invertible M-matrix and $(D-\M)^{-1}> \b0$ \label{prop:perturbation_mvtMatrix_DmM1}
			\item $\M$ irreducible and $\diag(D)>\b0$ $\Longrightarrow$ $D-\M$ nonsingular irreducible M-matrix and $(D-\M)^{-1}\gg \b0$ \label{prop:perturbation_mvtMatrix_DmM2}
		\end{enumerate}
	\end{proposition}
\end{frame}


\begin{frame}{Proof of Proposition~\ref{prop:perturbation_mvtMatrix}}
\ref{prop:perturbation_mvtMatrix_d}. From Lemma~\ref{lemma:mvt_matrix}(\ref{lemma:mvt_matrix_SB_eq0}), $s(\M)=0$. Therefore, using a ``spectrum shift'' Theorem~\ref{th:HJ_problem_1_2_P8}, $s(\M+d\II)=d$
\vfill
\noindent\ref{prop:perturbation_mvtMatrix_D}. These are direct consequences of applying the Perron-Frobenius Theorem~\ref{th:PerronFrobenius} to the essentially nonnegative matrix $\M+D$
\vfill
\end{frame}


\begin{frame}{Proof of Proposition~\ref{prop:perturbation_mvtMatrix} (cont'd)}
\noindent\ref{prop:perturbation_mvtMatrix_DmM1}.
Define $\underline{d}=\min_{i=1,\ldots,N}d_{ii}$. Then
\[
\diag (D)\gg \b0 \implies \underline{d}>0 \implies -\M\leq d\II-\M\leq D-\M
\]
From Theorem~\ref{th:Fiedler2008_K0}(\ref{th:Fiedler2008_K0_5}), $d\II-\M$ is an M-matrix. 
Since $s(\M)=0$, using a ``spectrum shift'', all eigenvalues of $d\II-\M$ have real parts larger
than $\underline{d}$, so $\underline{d}\II-\M$ is a nonsingular M-matrix. 
In turn, Theorem~\ref{th:Fiedler2008}(\ref{th:Fiedler2008_4}) $\implies$ $D-\M$ nonsingular M-matrix and Theorem~\ref{th:Fiedler2008}(\ref{th:Fiedler2008_11}) leads to the conclusion
\vfill
\noindent\ref{prop:perturbation_mvtMatrix_DmM2}. 
Suppose $\M$ irreducible. 
Let $\overline{d}=\max_{i=1,\ldots,N}d_{ii}>0$.
Then $D-\M$ is  irreducible and diagonally dominant with all columns $k=1,\ldots,N$ such that $d_{kk}=\overline{d}$ satisfying the strict diagonal
dominance requirement. (Other columns with nonzero entries in $D$ also satisfy the requirement.)
As a consequence, \cite[Theorem 1.11]{Varga2010} implies that $D-\M$ nonsingular and inverse positivity follows from Theorem~\ref{th:Fiedler2008_5_2_10}
\end{frame}

\begin{frame}{$-\M$ is also the Laplacian matrix of a digraph}
Note that $-\M$ is also the Laplacian matrix of a directed graph
\vfill 
As such, finer estimates of the location of eigenvalues are available; see, e.g.,  \cite{AgaevChebotarev2005}
\vfill
However, the main concern here is with the spectral abscissa, so this is not needed
\end{frame}


%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
\section{Local analysis of the model}
\begin{frame}{The \emph{population-free equilibrium} (PFE)}
	We find the PFE
	$\bP_s=\bP_t=\b0$ 
	\vfill
	At the PFE,
	\begin{equation}\label{eq:J_PFE}
	J_{\textrm{PFE}}^S = \M+(\D_s\oplus -\D_t)
	\end{equation}
	where $\D_s=\bG_s(\b0)=\diag(r_1,\ldots,r_S)$
	\vfill
	The matrix
	\[
	\D_s\oplus -\D_t=\diag (r_1,\ldots,r_S,-r_{S+1},\ldots,-r_N)
	\]
	has $S$ diagonal entries $>0$ and $N-S$ diagonal entries $<0$
\end{frame}


\begin{frame}{Mechanism of the existence proof}
	Start with $S=0$ (only sinks)
	\newline
	$\implies$ $\D_s$ vacuous and $\D_s\oplus -\D_t = \diag(-r_1,\ldots,-r_N)$ \newline
	$\implies$ $s(J_{PFE}^S)<0$
	\vfill
	Finish with $S=N$ (only sources)
	\newline
	$\implies$ $\D_t$ vacuous and $\D_s\oplus -\D_t = \diag(r_1,\ldots,r_N)$ \newline
	$\implies$ $s(J_{PFE}^S)>0$
	\vfill
	Eigenvalues of $J_{\textrm{PFE}}^S$ depend continuously of entries of $J_{\textrm{PFE}}^S$, so $s(J_{\textrm{PFE}}^S)$ changes signs, we are done.. if we are happy with a lot of uncertainty about behaviour of $s(J_{\textrm{PFE}}^S)$
\end{frame}


\begin{frame}{Continuous perturbation of the spectrum}
	\underline{For $S\in\{0,\ldots,N-1\}$}
	\[
	J_{\textrm{PFE}}^{S,\varepsilon} =
	\M+\diag(r_1,\ldots,r_S,\varepsilon,-r_{S+2},\ldots,-r_N)
	\]
	where $\varepsilon\in[-r_{S+1},r_{S+1}]$ is in $(S+1)^{\textrm{th}}$ position
	\vfill
	\underline{For $S\in[0,N]$}
	\begin{equation}\label{eq:xi_epsilon_ri}
	J_{\textrm{PFE}}^{S}=J_{\textrm{PFE}}^{\xi,\varepsilon},
	\quad\textrm{with}\quad
	\xi=\lfloor S\rfloor,
	\quad 
	\varepsilon= 2(S-\lfloor S\rfloor)r_i-r_i
	\end{equation}
	where $i=\lfloor S\rfloor+1$ if $S<N$ and $i=N$ when $S=N$
	\vfill
	\underline{Generally} we vary $\zeta$ continuously in each $[-r_{S+1},r_{S+1}]$
	\[
	J_{\textrm{PFE}}^{S,-r_{S+1}} = J_{\textrm{PFE}}^{S}
	\quad\textrm{and}\quad
	J_{\textrm{PFE}}^{S,r_{S+1}} = J_{\textrm{PFE}}^{S+1}
	\]
\end{frame}

\begin{frame}{The spectral abscissa $s(J_{\textrm{PFE}}^S)$ switches signs}
	\begin{lemma}\label{lemma:S_nonzero_at_ends}
		Let $\underline{r}=\min\limits_{i=1,\ldots, N} \{r_i\}$
		\vskip0.5cm
		Then $s(J_{\textrm{PFE}}^0) \leq -\underline{r} <0$ and  $s(J_{\textrm{PFE}}^N)\geq \underline{r} >0$
	\end{lemma}
\end{frame}

\begin{frame}{Proof of Lemma~\ref{lemma:S_nonzero_at_ends}}
	If $S=0$, then
	\[
	J_{\textrm{PFE}}^0=\M+\diag (-r_1,\ldots,-r_N)
	\]
	\vfill
	From Proposition~\ref{lemma:mvt_matrix}(\ref{lemma:mvt_matrix_SB_eq0}), $s(\M) = 0$. 
	Note that this follows from using the Gershgorin Disk Theorem ~\ref{th:Gershgorin}, where for $\M$, all Gershgorin disks are left of the imaginary axis and tangent to origin of the complex plane
	\vfill
	Then the centres of the Gershorin disks of $\M+\diag (-r_1,\ldots,-r_N)$ are shifted left by $r_1,\ldots,r_N$ while the radii remain the same
	\vfill
	As a consequence, the closest disk(s) to the origin of the complex plane have centre(s) $-\underline{r}$ and thus $s(\M+\diag (-r_1,\ldots,-r_N))\leq-\underline{r}<0$
\end{frame}

\begin{frame}{Proof of Lemma~\ref{lemma:S_nonzero_at_ends} (cont'd)}
	If $S=N$, then
	\[
	J_{\textrm{PFE}}^N=\M+\diag (r_1,\ldots,r_N)
	\]
	\vfill
	For $i=1,\ldots,N$, define $e_i=r_i-\underline{r}\geq 0$, then
	\[
	J_{\textrm{PFE}}^N=\M+\underline{r}\II+\diag (e_1,\ldots,e_N)
	\]
	where, by Proposition~\ref{prop:perturbation_mvtMatrix}(\ref{prop:perturbation_mvtMatrix_d}), $s(\M+\underline{r}\II)=\underline{r}>0$
\end{frame}

\begin{frame}{Proof of Lemma~\ref{lemma:S_nonzero_at_ends} (cont'd)}
	First, assume $\M$ irreducible
	\vfill
	Then $J_{\textrm{PFE}}^N$ is an irreducible essentially nonnegative matrix
	\vfill
	Since $J_{\textrm{PFE}}^N\geq \M+\underline{r}\II$, Theorem~\ref{th:Smith1995_4_3_2}(\ref{th:Smith1995_4_3_2_3}) $\implies$
	\[
		s(J_{\textrm{PFE}}^N)\geq s(\M+\underline{r}\II)=\underline{r}
	\]
	with the inequalities being strict if there exists at least one $e_i>0$
\end{frame}

\begin{frame}{Proof of Lemma~\ref{lemma:S_nonzero_at_ends} (cont'd)}
	Now assume that $\M$ reducible
	\vfill
	Then $\exists$ permutation matrix $P$ such that $P^T\M P$ is block upper triangular with irreducible blocks on the diagonal
	\vfill
	Call $C$ the number of such blocks, i.e., the number of strong components in the digraph of patches
	\vfill
	For $i=1,\ldots,C$, denote $n(i)$ the number of patches in strong component $i$ and $k(1),\ldots,k(n(i))$ their indices
	\vfill
	By abuse of notation, denote $\M_{ii}$ the corresponding diagonal block in the reduced form of $\M$
\end{frame}

\begin{frame}{Proof of Lemma~\ref{lemma:S_nonzero_at_ends} (cont'd)}
	Applying the permutation matrix $P$ to $J_{\textrm{PFE}}^N$ gives a block upper triangular matrix 
	\[
	P^TJ_{\textrm{PFE}}^NP
	\]
	with, for $i=1,\ldots,C$, the $n(i)\times n(i)$ diagonal blocks $\M_{ii}+E_i$ being irreducible and with
	\[
	E_i = \underline{r}\II
	+\diag\left(e_{k(1)},\ldots,e_{k(n(i))}\right)
	\]
\end{frame}


\begin{frame}{Proof of Lemma~\ref{lemma:S_nonzero_at_ends} (cont'd)}
	Fix $i=1,\ldots,C$ and let $\bv$ be a positive right eigenvector of $\M_{ii}+E_i$ corresponding to the spectral abscissa $s_1$ and $\bw$ be a positive left eigenvector of $\M_{ii}+\underline{r}\II$ corresponding to the spectral abscissa $s_2$.
	Then
	\begin{align*}
	s_1\bw^T\bv &= 
	\bw^T\left(\M_{ii}+\underline{r}\II +\diag(e_{k(1)},\ldots,e_{k(n(i))})\right)\bv \\
	&= \bw^T (\M_{ii}+\underline{r}\II)\bv + \bw^T \diag(e_{k(1)},\ldots,e_{k(n(i))})\bv \\
	&= s_2\bw^T\bv +\bw^T \diag(e_{k(1)},\ldots,e_{k(n(i))})\bv \\
	&\geq s_2\bw^T\bv
	\end{align*}
	the inequality being strict if at least one of the $e_{k(j)}$, $j=1,\ldots,n(i)$, is positive.
	Hence $s_1\geq s_2$, i.e., $s(\M_{ii}+E_i)\geq s(\M_{ii}+\underline{r}\II)$. 
	This is true for all diagonal blocks. Now, since $P^TJ_{\textrm{PFE}}^N P$ is block upper triangular, 
	\[
	s(J_{\textrm{PFE}}^N)=s(P^TJ_{\textrm{PFE}}^N P) =
	\max\{s(\M_{11}+E_1),\ldots,s(\M_{CC}+E_C)\}
	\]
\end{frame}

\begin{frame}{Proof of Lemma~\ref{lemma:S_nonzero_at_ends} (cont'd)}
	As $P^T(\M+\underline{r}\II)P$ is also block upper triangular,
	\[
	\underline{r} = s(\M+\underline{r}\II) =
	\max\{s(\M_{11}+\underline{r}\II),
	\ldots,
	s(\M_{11}+\underline{r}\II)\}
	\]
	\vfill
	As a consequence, $s(J_{\textrm{PFE}}^N)\geq \underline{r}>0$
\end{frame}

\begin{frame}
	Thus, $S^c$ necessarily lies in the open interval $(0,N)$.
	The following lemma is of interest and the method of proof of the second assertion is used again later
	\vfill
	\begin{lemma}\label{lemma:Mness_of_Jinterval}
	\begin{enumerate}
		\item \label{lemma:Mness_of_Jinterval_bounds}
		For all $S\in(0,N)\subset\IR$,
		\begin{equation}\label{ineq:bounds_J}
		J_{\textrm{PFE}}^{0}< J_{\textrm{PFE}}^{S}<
		J_{\textrm{PFE}}^{N}
		\end{equation}
		\item \label{lemma:Mness_of_Jinterval_increase}
		$J_{\textrm{PFE}}^{S}$ is an increasing function of $S$, in the sense that
	\begin{equation}\label{eq:J_increasing}
	\forall S_1,S_2\in[0,N]\subset\IR\textrm{ such that }S_1<S_2,
	\quad
	J_{\textrm{PFE}}^{S_1}< J_{\textrm{PFE}}^{S_2}
	\end{equation}
	%\item For all $S\in[0,S^c)$, $-J_{\textrm{PFE}}^{S}$ is a nonsingular M-matrix. The matrix $-J_{\textrm{PFE}}^{S}$ is a singular M-matrix.
	\end{enumerate}
	\end{lemma}
\end{frame}


\begin{frame}{Proof of Lemma~\ref{lemma:Mness_of_Jinterval}}
\ref{lemma:Mness_of_Jinterval_bounds}.
	Let $S\in(0,N)$ be fixed.
	Using \eqref{eq:xi_epsilon_ri}, this gives a pair $(\xi,\varepsilon)\in\{0,\ldots,N\}\times[-r_i,r_i]$, for $i=1\ldots N$, such that $J_{\textrm{PFE}}^{S}=J_{\textrm{PFE}}^{\xi,\varepsilon}$.
	We have
	\begin{align*}
	J_{\textrm{PFE}}^{\xi,\varepsilon}-J_{\textrm{PFE}}^{0} 
	&= \M+\diag(r_1,\ldots,r_{\xi},\varepsilon,-r_{\xi+2},\ldots,-r_N) \\
	&\quad -\M-\diag(-r_1,\ldots,-r_N) \\
	&= \diag(2r_1,\ldots,2r_{\xi},\varepsilon+r_{\xi+1},0,\ldots,0) \\
	&>\b0
	\end{align*}
	since $\varepsilon\in[-r_{\xi+1},r_{\xi+1}]$
	\vfill
	Computing $J_{\textrm{PFE}}^{N}-J_{\textrm{PFE}}^{\xi,\varepsilon}$ at the other endpoint works similarly, giving \eqref{ineq:bounds_J}
\end{frame}

\begin{frame}{Proof of Lemma~\ref{lemma:Mness_of_Jinterval} (cont'd)}
	\ref{lemma:Mness_of_Jinterval_increase}. Use \eqref{eq:xi_epsilon_ri} again to obtain two pairs $(\xi_1,\varepsilon_1)$ and $(\xi_2,\varepsilon_2)$, where, by the assumption $S_1<S_2$, $\xi_1\leq\xi_2$. First, assume that $\xi_1<\xi_2$. Then
	\begin{align*}
	J_{\textrm{PFE}}^{\xi_2,\varepsilon_2}-J_{\textrm{PFE}}^{\xi_1,\varepsilon_1} 
	&= \diag(r_1,\ldots,r_{\xi_2},\varepsilon_2,-r_{\xi_2+2},\ldots,-r_N) \\
	&\quad -
	\diag(r_1,\ldots,r_{\xi_1},\varepsilon_1,-r_{\xi_1+2},\ldots,-r_N) \\
	&= \diag(0,\ldots,0,r_{\xi_1+1}-\varepsilon_1,
	2r_{\xi_1+2},
	\ldots,
	2r_{\xi_2},\varepsilon_2+r_{\xi_2+1},0,\ldots,0) \\
	&>\b0
	\end{align*}
	since $\varepsilon_1 \in[-r_{\xi_1+1},r_{\xi_1+1}],$ and $\varepsilon_2\in[-r_{\xi_2+1},r_{\xi_2+1}]$. Now assume $\xi_1=\xi_2$. Then, since $S_1<S_2$, we find that $\varepsilon_1<\varepsilon_2$ and the diagonal matrix in the subtraction $J_{\textrm{PFE}}^{\xi_2,\varepsilon_2}-J_{\textrm{PFE}}^{\xi_2,\varepsilon_1}$ takes the form $\diag(0,\ldots,0,\varepsilon_2-\varepsilon_1,0,\ldots,0)>\b0$. So \eqref{eq:J_increasing} holds
\end{frame}


\begin{frame}
	\begin{proposition}\label{prop:spectral_abs_increasing}
		$\M$ reducible $\implies$ $s(J_{\textrm{PFE}}^S)$ nondecreasing for $S\in[0,N]$
		\vskip0.2cm
		$\M$ irreducible $\implies$ $s(J_{\textrm{PFE}}^S)$ increasing for $S\in[0,N]$
	\end{proposition}
	\vfill
	$\implies$ $\exists \S_{int}\subset(0,N)$ (resp. $S^c\in(0,N)$) s.t. PFE LAS if $S<\min(\S_{int})$ (resp. $S<S^c$) and PFE unstable if $S>\max(\S_{int})$ (resp. $S>S^c$)
\end{frame}

\begin{frame}{Proof of Proposition~\ref{prop:spectral_abs_increasing}}
	First, assume $\M$ is irreducible. Then, by Lemma~\ref{lemma:Mness_of_Jinterval} and the fact that $\M$ is irreducible (and thus so is $J_{\textrm{PFE}}^S$), Theorem~\ref{th:Smith1995_4_3_2}(\ref{th:Smith1995_4_3_2_3}) gives the result
\end{frame}

\begin{frame}{Proof of Proposition~\ref{prop:spectral_abs_increasing} (cont'd)}	
	Now, assume that $\M$ is reducible. $\implies$ $\exists$ permutation matrix $P$ such that $P^T\M P$ block upper triangular. Consider $S\in[0,N]\subset\IR$ and use \eqref{eq:xi_epsilon_ri} to obtain a corresponding pair $(\xi,\varepsilon)\in\{0,\ldots,N\}\times [-r_{\xi},r_{\xi}]$. Apply the same permutation to $J_{\textrm{PFE}}^{\xi,\varepsilon}$, giving
	\[
	P^TJ_{\textrm{PFE}}^{\xi,\varepsilon}P
	=
	\begin{pmatrix}
	\M_{11}+E_1 & \M_{12} & \cdots & \M_{1N} \\
	0 & \M_{22}+E_2 & & \\
	&&\ddots & \\
	0 & \cdots & 0 & \M_{CC}+E_C
	\end{pmatrix}
	\]
	where $C$ is the number of strong components in the digraph of patches and
	\[
	E_1\oplus\cdots\oplus E_C = P^T\diag(r_1,\ldots,r_{\xi},\varepsilon,-r_{\xi+2},\ldots,-r_N)P
	\]
	with matrix on right hand side having $\varepsilon$ as $(\xi+1)^{\textrm{th}}$ diagonal entry.
	As in the proof of Lemma~\ref{lemma:S_nonzero_at_ends}, we have denoted $\M_{ii}$ the diagonal blocks in the reduced form of $\M$
\end{frame}

\begin{frame}{Proof of Proposition~\ref{prop:spectral_abs_increasing} (cont'd)}	
	For $j=1,\ldots,C$, each of the matrices $\M_{jj}$ is irreducible; $C-1$ of the matrices $E_j$ are diagonal with entries $-r_i$ and $r_i$ on the diagonal (with some having only $-r_i$, some having only $r_i$ and some having both types of entries)
	\vfill
	The remaining $E_j$ matrix is diagonal, with potentially $-r_i$ and $r_i$ as the others, but also $\varepsilon$. Call $\eta\in\{1,\ldots,C\}$ the index of the strong component containing the matrix with $\varepsilon$
	\vfill
	As a consequence, for all $j=1,\ldots,C$, $\M_{jj}+E_j$ are irreducible essentially nonnegative matrices, with only matrix $\M_{\eta\eta}+E_\eta$ having an $\varepsilon$ added to one of its diagonal entries
\end{frame}

\begin{frame}{Proof of Proposition~\ref{prop:spectral_abs_increasing} (cont'd)}
	As $P^TJ_{\textrm{PFE}}^{\xi,\varepsilon}P$ is block upper triangular, we have
	\[
	s(P^TJ_{\textrm{PFE}}^{\xi,\varepsilon}P)
	=
	\max\left\{s(\M_{11}+E_1),\ldots,s(\M_{CC}+E_C)\right\}
	\]
	\vfill
	Except for $\M_{\eta\eta}+E_\eta$, all matrices $\M_{ii}+E_i$ have fixed spectral abscissa.
	Concerning matrix $\M_{\eta\eta}+E_\eta$, it is clear that the reasoning in the proof of Lemma~\ref{lemma:Mness_of_Jinterval}(\ref{lemma:Mness_of_Jinterval_increase}) carries through and thus,
	\[
	\forall \varepsilon_1,\varepsilon_2\in[-r_{\xi+1},r_{\xi+1}],
	\;
	\varepsilon_1<\varepsilon_2
	\implies
	J_{\textrm{PFE}}^{\xi,\varepsilon_1}
	< J_{\textrm{PFE}}^{\xi,\varepsilon_2}
	\]
	\vfill
	Hence $s(J_{\textrm{PFE}}^{\xi,\varepsilon})$ is the maximum of a set of $C$ functions, $C-1$ of which are constant in $\varepsilon$ and one of which is increasing in $\varepsilon$. 
	It now follows that $s(J_{\textrm{PFE}}^S)$ is a nondecreasing function of $S$, as desired
	%Using Theorem~\ref{th:Smith1995_4_3_2}(\ref{th:Smith1995_4_3_2_3}) gives the result in %terms of spectral abscissae.
\end{frame}

\begin{frame}{We now can do Part 1 of Theorem~\ref{th:main_result}}
	As $J_{\textrm{PFE}}^S$ is essentially nonnegative, its spectral abscissa $s(J_{\textrm{PFE}}^S)$ is an eigenvalue.
	Eigenvalues of $J_{\textrm{PFE}}^S$ depend continuously on $S$ (Theorem~\ref{th:HJ_2_4_9_2}). By Lemma~\ref{lemma:S_nonzero_at_ends}, $s(J_{\textrm{PFE}}^0)<0$ and $s(J_{\textrm{PFE}}^N)>0$, so by the Intermediate Value Theorem, there exists at least one point $S^c\in(0,N)$ such that $s(J_{\textrm{PFE}}^{S^c})=0$
	\vfill
	In the case where $\M$ is irreducible, $s(J_{\textrm{PFE}}^S)$ is increasing by Proposition~\ref{prop:spectral_abs_increasing} and as a consequence, $S^c$ is unique. In the case where $\M$ is reducible, $s(J_{\textrm{PFE}}^S)$ is nondecreasing, therefore there exists an interval $\S_{int}$, possibly reduced to a single point, such that $s(J_{\textrm{PFE}}^S)=0$ for all $S\in\S_{int}$
	\vfill
	The usual criteria for local asymptotic stability and instability of equilibria then imply the first part of Theorem~\ref{th:main_result} for $S<S^c$ and $S>S^c$ (irreducible case) or $S<\min(\S_{int})$ and $S>\max(\S_{int})$ (reducible case)
\end{frame}

\begin{frame}
	\begin{itemize}
		\item $\M$ reducible: $\exists \S_{int}\subset(0,N)$ s.t. PFE LAS if $S<\min(\S_{int})$ and PFE unstable if $S>\max(\S_{int})$
		\item $\M$ irreducible: $\exists S^c\in(0,N)$ s.t. PFE LAS if $S<S^c$ and PFE unstable if $S>S^c$
	\end{itemize}
	\vfill
	\begin{center}
		\includegraphics[width=0.49\textwidth]{FIGS/bifurcation_case_interval}
		\includegraphics[width=0.49\textwidth]{FIGS/bifurcation_case_unique}
	\end{center}
\end{frame}

\maxFrameImage{FIGS/vary_r_and_S_BA}
\maxFrameImage{FIGS/vary_r_and_S}
\maxFrameImage{FIGS/vary_r_and_S_zoom}

\begin{frame}
	As indicated by \cite{DeutschNeumann1985}, perturbation of the diagonal leads to convex changes in the spectral abscissa on each sub-interval
\end{frame}


\begin{frame}{We have a reproduction number when $\M$ irreducible}
	\begin{proposition}\label{prop:R0}
		Suppose $\M$ irreducible. 
		Define the \emph{basic reproduction number}
		\begin{equation}\label{eq:R0}
			\R_0 = \rho\left(
			\left(\M_s+\M_{st}(\D_t-\M_{t})^{-1}\M_{ts}\right)^{-1}\D_s
			\right)
		\end{equation}
		where $\M_s,\M_t,\M_{st},\M_{ts}$ are defined as in \eqref{eq:M_blocks}, $\D_s=\diag(r_1,\ldots,r_S)$ and $\D_t=\diag(r_{S+1},\ldots,r_N)$.
		Then
		\begin{equation}
			s(J_{\textrm{PFE}}^S)<0 \iff \R_0<1 \textrm{ and }
			s(J_{\textrm{PFE}}^S)>0 \iff \R_0>1
		\end{equation}
	\end{proposition}
\end{frame}

\begin{frame}{Proof of Proposition~\ref{prop:R0}}
		Write \eqref{eq:J_PFE} as
		\[
		J_{\textrm{PFE}}^S=\M+\tilde\D_s-\tilde D_t
		\]
		where $\tilde\D_s=\D_s\oplus\b0_{N-S\times N-S}$ and $\tilde \D_t=\b0_{S\times S}\oplus\D_t$.
		Let $-\alpha$ be the spectral abscissa of $\M+\tilde\D_s-\tilde\D_t$. 
		From Proposition~\ref{prop:perturbation_mvtMatrix}(\ref{prop:perturbation_mvtMatrix_D}), there is a vector $\bv\gg \b0$ such that
		\[
		(\M+\tilde\D_s-\tilde\D_t)\bv = -\alpha\bv
		\]
		In other words,
		\[
		\alpha\bv = (\tilde\D_t-\M)\bv-\tilde\D_s\bv
		\]
\end{frame}


\begin{frame}{Proof of Proposition~\ref{prop:R0} (cont'd)}
		By the assumption of irreducibility of $\M$, it follows from Proposition~\ref{prop:perturbation_mvtMatrix}(\ref{prop:perturbation_mvtMatrix_DmM2}) that $\tilde\D_t-\M$ is an irreducible nonsingular M-matrix and $(\tilde\D_t-\M)^{-1}\gg\b0$
		\vfill
		Then
		\[
		\alpha\left(
		\tilde\D_t-\M
		\right)^{-1}\bv
		=\bv -\left(
		\tilde\D_t-\M
		\right)^{-1}
		\tilde\D_s\bv
		\]
		with the matrix $(\tilde\D_t-\M)^{-1}\tilde\D_s>\b0$
		\vfill
		As a consequence, from the Perron-Frobenius Theorem~\ref{th:PerronFrobenius}, the spectral radius of $(\tilde\D_t-\M)^{-1}\tilde\D_s$ is an eigenvalue and is associated to a nonnegative eigenvector
\end{frame}
		
\begin{frame}{Proof of Proposition~\ref{prop:R0} (cont'd)}
		Let $\bu$ be such an eigenvector, normalised so that $\bu^T\bv=1$.
		Then
		\[
		\alpha\bu^T
		\left(\tilde\D_t-\M\right)^{-1}\bv =
		\bu^T\bv
		\left(1-
		\rho\left\{\left(\tilde\D_t-\M\right)^{-1}\tilde\D_s\right\}
		\right)
		\]
		\vfill
		Thus
		\[
		\alpha>0 \iff \rho\left\{\left(\tilde\D_t-\M\right)^{-1}\tilde\D_s\right\} <1
		\]
		and
		\[
		\alpha<0 \iff \rho\left\{\left(\tilde\D_t-\M\right)^{-1}\tilde\D_s\right\} >1
		\]
\end{frame}

\begin{frame}{Proof of Proposition~\ref{prop:R0} (cont'd)}
		From the structure of $\tilde\D_s$, the spectral radius of $(\tilde\D_t-\M)^{-1}\tilde\D_s$ is the spectral radius of 
		\[
		\left(\tilde\D_t-\M\right)^{-1}_{[11]}\D_s
		\]
		where $(\tilde\D_t-\M)^{-1}_{[11]}$ is the (1,1) block in $(\tilde\D_t-\M)^{-1}$
		\vfill
		Writing $\M$ as \eqref{eq:M_blocks}, we have by the formula for the inverse of a $2\times 2$ block matrix that 
		\[
		\left(\tilde\D_t-\M\right)^{-1}_{[11]}=(-\M_s-\M_{st}(\D_t-\M_t)^{-1}\M_{ts})^{-1}
		\]
\end{frame}

\begin{frame}{Proof of Proposition~\ref{prop:R0} (cont'd)}
		Clearly,
		\begin{multline*}
			\rho\left(
			(-\M_s-\M_{st}(\D_t-\M_t)^{-1}\M_{ts})^{-1}\D_s
			\right) \\
			=
			\rho\left(
			(\M_s+\M_{st}(\D_t-\M_t)^{-1}\M_{ts})^{-1}\D_s
			\right)
		\end{multline*}
		giving the result
\end{frame}

\section{Global behaviour}
\begin{frame}{So..}
	we are done!
	\vfill
	.. Are we? The result is only local, can we go further?
\end{frame}

\begin{frame}{System \eqref{sys:simple_model} is cooperative}
	Jacobian of \eqref{sys:simple_model}:
	\begin{equation}\label{eq:Jacobian_anywhere}
	J(\bP_s,\bP_t) = 
	\begin{pmatrix}
	\bG_s'(\bP_s)\bP_s+\bG_s(\bP_s)+\M_s & \M_{st} \\
	\M_{ts} & -\D_t+\M_t
	\end{pmatrix}
	\end{equation}
	where
	\[
	\bG_s'(\bP_s) = \diag \left(-\frac{r_1}{K_1},\ldots,-\frac{r_S}{K_s}\right)
	\]
	\vfill
	Thus
	\[
	J(\bP_s,\bP_t) = \M+ \left((\bG_s'(\bP_s)\bP_s+\bG_s(\bP_s))\oplus -\D_t\right)
	\]
	with
	$\bG_s'(\bP_s)\bP_s+\bG_s(\bP_s)$ and $-\D_t$ diagonal
	\vfill
	$\implies$ system \eqref{sys:simple_model} is cooperative
\end{frame}


\begin{frame}{A theorem of Hirsch}
	So, to move forward, we would like to apply the following result
	\vfill
	\begin{theorem}[Th. 6.1 in Hirsch (1984) -- BAMS 11(1)]
		Let $\bF$ be a $C^1$ vector field in $\IR^n$ with flow $\phi$ preserving $\IR_+^n$ for $t>0$ and strongly monotone in $\IR_+^n$. 
		Suppose that the origin is an equilibrium and all trajectories in $\IR_+^n$ are bounded. Suppose the matrix-valued map $D\bF:\IR_+^n\to \IR^{n\times n}$ is strictly antimonotone, i.e., 
		\[
		\bx>\by\implies D\bF(\bx)<D\bF(\by)
		\]
		\vskip0.5cm
		Then either all trajectories in $\IR_+^n$ go to the origin, or there exists a unique equilibrium $\bP^\star\in\mathsf{Int}\IR_+^n$ and all trajectories in $\IR_+^n\setminus\{\b0\}$ limit to $\bP^\star$
	\end{theorem}
\end{frame}

\begin{frame}{OK, nice, but..}
	Take
	\[
	\bP_1 = (0,\ldots,0,\star,\ldots,\star) \textrm{ and }
	\bP_2 = (0,\ldots,0,\star,\ldots,\star)
	\]
	have their first $S$ entries zero, i.e., $\bP_1=(\b0_s,\bP_t^1)$ and $\bP_2=(\b0_s,\bP_t^2)$; assume $\bP_1>\bP_2$, i.e., $\bP_t^1>\bP_t^2$
	\vfill
	Then
	\begin{align*}
	J(\b0_s,\bP_t^1) &= \M+ \left((\bG_s'(\b0_s)\b0_s+\bG_s(\b0_s))\oplus -\D_t\right) \\
	&= \M+\left(\D_s\oplus -\D_t\right) \\
	&= J(\b0_s,\bP_t^2)
	\end{align*}
	i.e.,
	\[
	J^S_{\bP_1}=J^S_{\bP_2}
	\]
	\vfill
	$\implies$ \eqref{sys:simple_model} is not strictly antimonotone
\end{frame}


\begin{frame}{(non) lasciate ogne sperenza, voi ch'intrate}
	Except for strict antimonotonicity of $\bF$, all hypotheses of [Hirsch (1984) -- Th. 6.1] are satisfied:
	\begin{itemize}
		\item in the case $\M$ irreducible, \eqref{sys:simple_model} is strongly monotone (by [Hirsch (1984) -- Th. 1.7])
		\item the origin is an equilibrium
		\item all solutions of \eqref{sys:simple_model} are bounded in $\IR_+^N$ (not shown here, but not hard)
	\end{itemize}
	\vfill
	$\implies$ by other results (\emph{e.g.}, Hirsch \emph{ibid}), there exists $\bP^*\gg \b0$
	\vfill
	What is the use of strict antimonotonicity in the proof of [Hirsch (1984) -- Th. 6.1]? .. To show uniqueness of $\bP^*$
\end{frame}

\begin{frame}
		More precisely: let $\bz\in(\b0,\bP^*)$, where $\bP^*\gg\b0$ is a nontrivial equilibrium
		\vfill
		Strict antimonotonicity $\implies$ $\bF(\bz)>\b0$, and we can then proceed with the remainder of the proof of [Hirsch (1984) -- Th. 6.1]
		\vfill
		Let us show that we indeed have $\bF(\bz)>\b0$ for \eqref{sys:simple_model}, despite the lack of strict antimonotonicity
		\vfill
		As in [Hirsch (1984) -- Th. 6.1]: for $i = 1,\ldots,N$, let 
		\begin{align*}
		g_i :  [0,1] &\to\IR \\
		s &\mapsto F_i(s\bP^*)
		\end{align*}
\end{frame}

\begin{frame}
	Then $g_i(0)=g_i(1)=0$ for $i=1,\ldots,N$ and, for $i=S+1,\ldots,N$ 
	(sinks),
		\[
		g_i(s) = -r_isP_i^*+\sum_{j=1}^Nm_{ij}sP_j^*
		= \left(r_iP_i^*+\sum_{j=1}^Nm_{ij}P_j^*\right)s=0
		\]
		However, for $i=1,\ldots,S$ (sources),
		\[
		g_i(s) = r_i\left(1-\frac{sP_i^*}{K_i}\right)sP_i^*
		+\sum_{j=1}^Nm_{ij}sP_j^*
		\]
		Ha!
		\[
		g_i''(s)=-\frac{2r_iP_i^{*2}}{K}<0,\quad i=1,\ldots,S
		\]
		\vfill
		$\implies$ for $i=1,\ldots,S$, $g_i(s)>0$ when $s\in(0,1)$
		
		$\implies$ 
		when $S>0$, $\bF(\bz)>\b0$, $\forall\bz\in(\b0,\bP^*)$
		
\end{frame}
		
\begin{frame}
	And we can then carry on with the remainder of the proof of [Hirsch (1984) -- Th. 6.1]
	\vfill
	To finish, the case $S=0$ is easy: 
	\[
	\left(\sum_{i=1}^{N}{P_i}\right)' 
	= -\sum_{i=1}^N r_iP_i < 0
	\]
	since at least one of the $P_i(0)>0$ 
	\vfill 
	$\implies$ $\left(\sum_{i=1}^{N}{P_i}\right)\to 0$ $\implies$ $\lim_{t\to\infty}P_i(t)=0$ for $i=1,\ldots,N$
	\vfill
	Et hop! $\square$
\end{frame}

\begin{frame}{To conclude (mathematically)}
	\begin{theorem}\label{th:main_result}
		There exists a critical \emph{interval} $\S_{int}\subset(0,N)\subset\IR$ s.t.
		\begin{itemize}
			\item $S<\min(\S_{int})$ $\implies$ PFE LAS
			\item $S>\max(\S_{int})$ $\implies$ PFE instable
		\end{itemize}
		\vskip0.5cm
		Additionally, if the patch digraph is strongly connected, then
		\begin{itemize}
			\item $\S_{int}$ is reduced to a \emph{point}  $S^c$
			\item $S<S^c$ $\implies$ PFE GAS
			\item $S>S^c$ $\implies$ $\exists!\bP^*\gg\b0$ GAS for $\IR_+^N\setminus\{\b0\}$
		\end{itemize}
	\end{theorem}
\end{frame}



%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\section{An interesting special case}
\begin{frame}
	In the 2 figures that follow:
	\begin{itemize}
		\item $N=50$
		\item $r=r_i$, $\forall i=1,\ldots,N$
		\item $m_{ij}=m$, $\forall i,j=1,\ldots,N$ s.t. $m_{ij}>0$
		\item plot is value of $S^c$ as a function of $m$ and $r$
	\end{itemize}
	\vfill
	Figure 1: ring of patches
	\vfill
	Figure 2: complete digraph
\end{frame}


\maxFrameImage{FIGS/Sc_vs_r_and_m_ring}
\maxFrameImage{FIGS/Sc_vs_r_and_m_complete}

\begin{frame}{Case of complete homogeneous movement}
	\begin{proposition}\label{prop:Sc_mvt_complete_homog}
		Suppose that the movement digraph is complete and that $m_{ij}=m$ for $i,j=1,\ldots,N$, $i\neq j$
		\vskip0.2cm
		Suppose that $S\in\{1,\ldots,N-1\}$, that for $i=1,\ldots,S$, $r_i=r_s$ and that for $i=S+1,\ldots,N$, $r_i=r_t$
		\vskip0.2cm
		Then
		\begin{equation}\label{eq:Sc_mvt_complete_homog}
		S^c = \frac{mNr_t-r_sr_t}{m(r_s+r_t)}
		\end{equation}
	\end{proposition}
	\vfill
	If $r_s=r_t=r$, then
	\begin{equation}\label{eq:Sc_mvt_complete_homog_equal_r}
	S^c=\frac N2-\frac{r}{2m}
	\end{equation}
\end{frame}

\maxFrameImage{FIGS/Sc_vs_rs_and_rt_complete}
	
\begin{frame}{Proof of Prop~\ref{prop:Sc_mvt_complete_homog} uses equitable partitions}
	Section 9.3 in \emph{Algebraic Graph Theory}, Godsil \& Royle (2013) 
	\vfill
	An \textbf{equitable partition} $\pi$ splits a graph $X$ into \textbf{cells} $\C_i$, $i=1,\ldots,r$, s.t. for a vertex $u$ in cell $\C_i$, the number of neighbours in cell $\C_j$ is a constant $b_{ij}$ that does not depend on $u$ 
	\vfill
	$\iff$ the subgraph of $X$ induced by each cell is regular [vertices have same degree] and edges joining two distinct cells form a semiregular bipartite graph [vertices have same degree in each bipartite component]
	\vfill
	The digraph with the $r$ cells of $\pi$ as vertices and the $b_{ij}$ arcs from the $i^{\textrm{th}}$ to the $j^{\textrm{th}}$ cell of $\pi$ is the \textbf{quotient} $X/\pi$ of $X$ on $\pi$. The adjacency matrix of $X/\pi$ is $A(X/\pi)=[b_{ij}]$
\end{frame}

\begin{frame}{Characterising an equitable partition}
\begin{lemma}[A friendly characterisation]
	$X$ graph, $A(X)$ its adjacency matrix, $\pi$ a partition of $V(X)$ with characteristic matrix $P$. Then
	\begin{center}
		$\pi$ equitable $\iff$ column space of $P$ is $A$-invariant
	\end{center}
\end{lemma}
\end{frame}

\begin{frame}
	Write
	\begin{equation}\label{eq:J_PFE_equi_part}
	J_{\textrm{PFE}}^S = \begin{pmatrix}
		m\IJ - Nm\II + r_s\II & m \IJ \\
		m\IJ & m\IJ - Nm\II - r_t\II
	\end{pmatrix}
	\end{equation}
	with $\IJ$ matrix of all 1's
	\vfill
	Consider \eqref{eq:J_PFE_equi_part} as the adjacency matrix of a digraph $\G$
	\vfill
	Suppose partition $\pi$ splits $\G$ in two cells, $\{S_i\}_{i=1,\ldots,S}$ (sources) and $\{T_i\}_{i=S+1,\ldots,N}$ (sinks)
	\vfill
	The characteristic matrix of $\pi$ is the $N\times 2$-matrix
	\[
		C = 
		\begin{pmatrix}
		\11_S & \b0_S \\
		\b0_{N-S} & \11_{N-S}
		\end{pmatrix}
	\]
\end{frame}

\begin{frame}
	We have
	\[
		J_{\textrm{PFE}}^S \11 = 
		J_{\textrm{PFE}}^S\begin{pmatrix}
		\11_S\\ \11_{N-S}
		\end{pmatrix}=
		\begin{pmatrix}
		r_s \11_S \\
		-r_t \11_{N-S}
		\end{pmatrix}
	\]
	\vfill
	Thus the column space of $C$ is $J_{\textrm{PFE}}^S$-invariant $\implies$ $\pi$ is equitable
\end{frame}

\begin{frame}{Properties of equitable partitions}
\begin{lemma}
	$\pi$ equitable partition of graph $X$ with characteristic matrix $P$, and $B=A(X/\pi)$. Then $AP = PB$ and
	$B=(P^TP)^{-1}P^T AP$
\end{lemma}
\vfill
\begin{theorem}
	$\pi$ equitable partition of graph $X$ $\implies$ characteristic polynomial of $A(X/\pi)$ divides characteristic polynomial of $A(X)$
\end{theorem}
\end{frame}

\begin{frame}
	$\implies$ the quotient matrix $B_{\textrm{PFE}}^S$ satisfies
\[
B_{\textrm{PFE}}^S = (C^TC)^{-1}C^TJ_{\textrm{PFE}}^SC
\label{eq:formulaJPPB}
\]

\[
\implies B_{\textrm{PFE}}^S = \begin{pmatrix}
mS - mN +r_s & m(N-S) \\
mS & -(mS + r_s)
\end{pmatrix}
\]
\vfill
And $\sigma(B_{\textrm{PFE}}^S) \subset \sigma(J_{\textrm{PFE}}^S)$
\end{frame}

\begin{frame}
	$B_{\textrm{PFE}}^S$ essentially nonnegative (and clearly irreducible)
	\[
	\implies\exists! \bv_p\gg \b0 
	\textrm{ s.t. }  B_{\textrm{PFE}}^S\bv_p = \lambda_p \bv_p=s(B_{\textrm{PFE}}^S)\bv_p
	\]
	\vfill 
	Then $J_{\textrm{PFE}}^SC=CB_{\textrm{PFE}}^S$
	\vfill
	So
	\begin{equation*}
		J_{\textrm{PFE}}^SC\bv_p = CB_{\textrm{PFE}}^S\bv_p = \lambda_p C \bv_p
	\end{equation*}
	and $C\bv_p$ is an eigenvector of $J_{\textrm{PFE}}^S$ that is also $\gg\b0$
	\vfill
	As the only eigenvector $\gg\b0$ of $J_{\textrm{PFE}}^S$ corresponds to $s(J_{\textrm{PFE}}^S)$, we have $s(J_{\textrm{PFE}}^S) = s(B_{\textrm{PFE}}^S)$ 
\end{frame}

\begin{frame}	
	To compute $S^c$, recall $S^c$ is value of $S$ where PFE loses stability
	\vfill
	Consider $B_{\textrm{PFE}}^S$. We have $\tr(B_{\textrm{PFE}}^S) = -mN +r_s-r_t$ and
	\[
		\det(B_{\textrm{PFE}}^S) = -mS(r_s+r_t) - r_sr_t  + mNr_t
	\]
	\vfill
	One shows easily that $\det(\cdot)$ gouverns stability
	\vfill
	\[
		\implies S^c = \frac{mNr_t-r_sr_t}{m(r_s+r_t)}
	\]
	\flushright$\square$
\end{frame}


%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\appendix
\section{Appendix -- Used results}
\setcounter{theorem}{0}
\renewcommand{\thetheorem}{A.\arabic{theorem}}

\begin{frame}{\cite{HornJohnson2013}}
	\begin{theorem}[{\cite[Problem 1.2.P8]{HornJohnson2013}}]
		\label{th:HJ_problem_1_2_P8}
		Let $A\in\M_n$ and $\lambda\in\IC$ be given. 
		Suppose that the eigenvalues of $A$ are $\lambda_1,\ldots,\lambda_n$.
		Explain why $p_{A+\lambda\II}(t)=p_A(t-\lambda)$ and deduce from this identity that the eigenvalues of $A+\lambda\II$ are $\lambda_1+\lambda,\ldots,\lambda_n+\lambda$
	\end{theorem}
\end{frame}

\begin{frame}
	\begin{theorem}[{\cite[Theorem 2.4.9.2]{HornJohnson2013}}]
		\label{th:HJ_2_4_9_2}
		Let an infinite sequence $A_1,A_2,\ldots\in\M_n$ be given and suppose that $\lim_{k\to\infty} A_k = A$ (entrywise convergence)
		\vskip0.5cm
		Let $\lambda(A) = [\lambda_1(A)\cdots\lambda_n(A)]^T$ and $\lambda(A_k) = [\lambda_1(A_k)\cdots \lambda_n(A_k)]^T$ be given presentations of the eigenvalues of $A$ and $A_k$, respectively, for $k=1,2,\ldots$. Let $S_n = \{\pi : \pi\text{ is a permutation of }\{1,2,\ldots,n\}\}$. 
		Then for each given $\varepsilon>0$ there exists a positive integer $N = N(\varepsilon)$ such that
		\[
			\min_{\pi\in S_n}\max_{i=1,\ldots,n}\left\{|\lambda_{\pi(i)}(A_k)-\lambda_i(A)|\right\}\leq\varepsilon\text{ for all }k\geq N
		\]
	\end{theorem}
\end{frame}

\begin{frame}{\cite{Varga2010}}
	Let $A\in \M_n(\IC)$. Denote $N=\{1,\ldots,n\} $. For $i\in N$, define 
	\[r_i (A)= \sum\limits_{j\in N\setminus \{i\}} | a_{ij}|\]
	to be
	the $i$th deleted row sums of $A$. Assume that $r_i(A)=0$ if $n=1$. Let 
	\[\Gamma_i(A)=\{z\in \IC \mid |z-a_{ii}|\leq r_i(A)\} \qquad i\in N\]
	 be the $i$th \textbf{Gershgorin disk}\index{Gershgorin disk} of $A$ and 
	\[\Gamma(A)= \bigcup\limits_{i\in N} \Gamma_i (A)\]
	be the \textbf{Gershgorin set}\index{Gershgorin set} of $A$. $\Gamma_i$ and $\Gamma$ are closed and bounded in $\IC$. $\Gamma_i(A)$ is a disk centred at $a_{ii}$ and with radius $r_i(A)$, $i\in N$.
\end{frame}
	
	
\begin{frame}
	\begin{theorem}[Gershgorin, 1931]
		\label{th:Gershgorin}
	For all $A\in \M_{n}(\IC)$ and for all $\lambda\in \sigma(A)$, there exists $k\in \IN$ such that 
	\[
	  |\lambda -a_{kk}|\leq r_k(A)
	\]
	i.e., $\lambda\in \Gamma_k(A)$ and thus $\lambda \in \Gamma(A)$. Since this is true for all $\lambda$, we have 
	\[
	  \sigma(A)\subseteq \Gamma(A)
	\]
	\end{theorem}
	\vfill
	\begin{remark}
	This also works with deleted column sums; indeed, just consider $A^T$ in this case. However, this typically gives different disks
	\end{remark}
\end{frame}

\begin{frame}{\cite{Fiedler2008}}
	\begin{theorem}[Perron-Frobenius {\cite[Theorem 4.2.1]{Fiedler2008}}]
		\label{th:PerronFrobenius}
		$A\geq 0$ be irreducible. Then $\rho(A)$ is a simple positive eigenvalue of $A$ and there exists a positive eigenvector $\bx$ associated to $\rho(A)$. No other nonnegative vector is associated with any other eigenvalue of $A$
	\end{theorem}
\end{frame}

\begin{frame}
	\begin{definition}
	\label{def:Z_n}
	A matrix is of class $Z_n$ if it is in $\M_n(\IR)$ and such that $a_{i,j}\leq 0$, $i \neq j$, $i,j=1,\ldots,n$
	\[
		Z_n=\{A\in \M_n: a_{i,j}\leq 0, i\neq j\}
	\]
	We also say that $A\in Z_n$ has the \defword{$Z$-sign pattern}
	\end{definition}
\end{frame}
	
	
\begin{frame}
	\begin{theorem}[{\cite[Theorem 5.1.1]{Fiedler2008}}]
	\label{th:Fiedler2008}
	Let $A\in Z_n$. TFAE and define matrices of class $K$ (or nonsingular $M$-matrix)
	\begin{enumerate}
		\item There is a nonnegative vector $x$ such that $Ax>0$
		\item There is a positive vector $x$ such that $Ax>0$
		\item There is a diagonal matrix $\diag(D)>0$ such that the entries in $AD=[w_{ik}]$ are such that 
		\[w_{ii}> \sum\limits_{k\neq i} | w_{ik}| \forall i\]
		\item For any $B\in Z_n$ such that $A\geq A$, then $B$ is nonsingular 
		\label{th:Fiedler2008_4}
		\item Every real eigenvalue of any principal submatrix of $A$ is positive.
		\item All principal minors of $A$ are positive
	\end{enumerate}
	\end{theorem}
\end{frame}
	
\begin{frame}
	\addtocounter{theorem}{-1}
	\begin{theorem}[{\cite[Theorem 5.1.1]{Fiedler2008}} (continued)]
	\begin{enumerate}
		\setcounter{enumi}{6}
		\item For all $k= 1, \dots, n$, the sum of all principal minors is positive
		\item Every real eigenvalue of $A$ is positive
		\item There exists a matrix $C\geq 0$ and a number $k > \rho(A)$ such that $A= k\mathbb{I}-C$
		\item There exists a splitting $A=P-Q$ of the matrix $A$ such that $P^{-1}\geq 0$, $Q\geq 0$, and $\rho(P^{-1}Q<1)$
		\item $A$ is nonsingular and $A^{-1}\geq 0$
		\label{th:Fiedler2008_11}
		\item
		\item
		\item
		\item
		\item
		\item
		\item The real part of any eigenvalue of $A$ is positive \label{th:Fiedler2008_18}
	\end{enumerate}
	\end{theorem}
\end{frame}
	

\begin{frame}
	\begin{theorem}[{\cite[Theorem 5.2.1]{Fiedler2008}}]
	\label{th:Fiedler2008_K0}
	Let $A\in Z_n$. TFAE and define matrices of class $K_0$
	\begin{enumerate}
		\item $A+\varepsilon \II\in K$ for all $\varepsilon>0$ 
		\label{th:Fiedler2008_K0_1}
		\item Every real eigenvalue of a principal submatrix of $A$ is nonnegative
		\item All principal minors of $A$ are nonnegative
		\item The sum of all principal minors of order $k= 1, \dots, n$ is nonnegative
		\item Every real eigenvaue of $A$ is nonegative
		\label{th:Fiedler2008_K0_5}
		\item There exists $C\geq 0$ and $k\geq \rho(C)$ such that $A= k \mathbb{I}-C$
		\item Every eigenvalue of $A$ has nonnegative real part
	\end{enumerate}
	\end{theorem}
\end{frame}
	

\begin{frame}
	\begin{theorem}[{\cite[Theorem 5.2.10]{Fiedler2008}}]
	\label{th:Fiedler2008_5_2_10}
	Let $A\in Z$ be irreducible. TFAE
	\begin{enumerate}
		\item $\exists\bx>\b0$ s.t. $A\bx>0$
		\item $\exists\bx>\b0$ s.t. $A\bx\geq\b0$ and $A\bx\neq\b0$
		\item $A\in K$
		\item $A^{-1}>0$
	\end{enumerate}
	\end{theorem}
\end{frame}

\begin{frame}{\cite{Smith1995}}
	\begin{theorem}[{\cite[Corollary 4.3.2]{Smith1995}}]
		\label{th:Smith1995_4_3_2}
		Let $A$ be quasi-positive. Then $s(A)\in\sigma(A)$ and $\exists\bv>\b0$ such that $A\bv=s(A)\bv$.
		Moreover, $\Re\lambda<s(A)$ for all $\lambda\in\sigma(A)\setminus\{s(A)\}$. If, in addition, $A$ is irreducible, then
		\begin{enumerate}
			\item $s(A)$ has algebraic multiplicity 1
			\item $\bv\gg\b0$ and any eigenvector $\bw>\b0$ of $A$ is a positive multiple of $\bv$
			\item If $B$ is a matrix satisfying $B>A$, then $S(B)>s(A)$
			\label{th:Smith1995_4_3_2_3}
			\item If $s(A)<0$ then $-A^{-1}\gg\b0$
		\end{enumerate}
	\end{theorem}
\end{frame}

\bibliographystyle{apalike}
\bibliography{math,biblio_Arino_Julien,ecology}


\end{document}
